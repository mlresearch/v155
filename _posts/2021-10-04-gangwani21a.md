---
title: Harnessing Distribution Ratio Estimators for Learning Agents with Quality and
  Diversity
abstract: Quality-Diversity (QD) is a concept from Neuroevolution with some intriguing
  applications to Reinforcement Learning. It facilitates learning a population of
  agents where each member is optimized to simultaneously accumulate high task-returns
  and exhibit behavioral diversity compared to other members. In this paper, we build
  on a recent kernel-based method for training a QD policy ensemble with Stein variational
  gradient descent. With kernels based on $f$-divergence between the stationary distributions
  of policies, we convert the problem to that of efficient estimation of the ratio
  of these stationary distributions. We then study various distribution ratio estimators
  used previously for off-policy evaluation and imitation and re-purpose them to compute
  the gradients for policies in an ensemble such that the resultant population is
  diverse and of high-quality.
paperid: '496'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gangwani21a
month: 0
tex_title: Harnessing Distribution Ratio Estimators for Learning Agents with Quality
  and Diversity
firstpage: 2206
lastpage: 2215
page: 2206-2215
order: 2206
cycles: false
bibtex_author: Gangwani, Tanmay and Peng, Jian and Zhou, Yuan
author:
- given: Tanmay
  family: Gangwani
- given: Jian
  family: Peng
- given: Yuan
  family: Zhou
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/gangwani21a/gangwani21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v155/gangwani21a/gangwani21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
