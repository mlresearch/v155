---
title: Learning 3D Dynamic Scene Representations for Robot Manipulation
abstract: '3D scene representation for robot manipulation should capture three key
  object properties: permanency - objects that become occluded over time continue
  to exist; amodal completeness - objects have 3D occupancy, even if only partial
  observations are available; spatiotemporal continuity - the movement of each object
  is continuous over space and time. In this paper, we introduce 3D Dynamic Scene
  Representation (DSR), a 3D volumetric scene representation that simultaneously discovers,
  tracks, reconstructs objects, and predicts their dynamics while capturing all three
  properties. We further propose DSR-Net, which learns to aggregate visual observations
  over multiple interactions to gradually build and refine DSR. Our model achieves
  state-of-the-art performance in modeling 3D scene dynamics with DSR on both simulated
  and real data. Combined with model predictive control, DSR-Net enables accurate
  planning in downstream robotic manipulation tasks such as planar pushing. Code and
  data are available at dsr-net.cs.columbia.edu.'
paperid: '35'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu21b
month: 0
tex_title: Learning 3D Dynamic Scene Representations for Robot Manipulation
firstpage: 126
lastpage: 142
page: 126-142
order: 126
cycles: false
bibtex_author: Xu, Zhenjia and He, Zhanpeng and Wu, Jiajun and Song, Shuran
author:
- given: Zhenjia
  family: Xu
- given: Zhanpeng
  family: He
- given: Jiajun
  family: Wu
- given: Shuran
  family: Song
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/xu21b/xu21b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
