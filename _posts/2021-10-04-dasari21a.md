---
title: Transformers for One-Shot Visual Imitation
abstract: Humans are able to seamlessly visually imitate others, by inferring their
  intentions and using past experience to achieve the same end goal. In other words,
  we can parse complex semantic knowledge from raw video and efficiently translate
  that into concrete motor control. Is it possible to give a robot this same capability?
  Prior research in robot imitation learning has created agents which can acquire
  diverse skills from expert human operators. However, expanding these techniques
  to work with a single positive example during test time is still an open challenge.
  Apart from control, the difficulty stems from mismatches between the demonstrator
  and robot domains. For example, objects may be placed in different locations (e.g.
  kitchen layouts are different in every house). Additionally, the demonstration may
  come from an agent with different morphology and physical appearance (e.g. human),
  so one-to-one action correspondences are not available. This paper investigates
  techniques which allow robots to partially bridge these domain gaps, using their
  past experience. A neural network is trained to mimic ground truth robot actions
  given context video from another agent, and must generalize to unseen task instances
  when prompted with new videos during test time. We hypothesize that our policy representations
  must be both context driven and dynamics aware in order to perform these tasks.
  These assumptions are baked into the neural network using the Transformers attention
  mechanism and a self-supervised inverse dynamics loss. Finally, we experimentally
  determine that our method accomplishes a 2x improvement in terms of task success
  rate over prior baselines in a suite of one-shot manipulation tasks.
paperid: '463'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dasari21a
month: 0
tex_title: Transformers for One-Shot Visual Imitation
firstpage: 2071
lastpage: 2084
page: 2071-2084
order: 2071
cycles: false
bibtex_author: Dasari, Sudeep and Gupta, Abhinav
author:
- given: Sudeep
  family: Dasari
- given: Abhinav
  family: Gupta
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/dasari21a/dasari21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
