---
title: Model-Based Inverse Reinforcement Learning from Visual Demonstrations
abstract: Scaling model-based inverse reinforcement learning (IRL) to real robotic
  manipulation tasks with unknown dynamics remains an open problem. The key challenges
  lie in learning good dynamics models, developing algorithms that scale to high-dimensional
  state-spaces and being able to learn from both visual and proprioceptive demonstrations.
  In this work, we present a gradient-based inverse reinforcement learning framework
  that utilizes a pre-trained visual dynamics model to learn cost functions when given
  only visual human demonstrations. The learned cost functions are then used to reproduce
  the demonstrated behavior via visual model predictive control. We evaluate our framework
  on hardware on two basic object manipulation tasks.
paperid: '432'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: das21a
month: 0
tex_title: Model-Based Inverse Reinforcement Learning from Visual Demonstrations
firstpage: 1930
lastpage: 1942
page: 1930-1942
order: 1930
cycles: false
bibtex_author: Das, Neha and Bechtle, Sarah and Davchev, Todor and Jayaraman, Dinesh
  and Rai, Akshara and Meier, Franziska
author:
- given: Neha
  family: Das
- given: Sarah
  family: Bechtle
- given: Todor
  family: Davchev
- given: Dinesh
  family: Jayaraman
- given: Akshara
  family: Rai
- given: Franziska
  family: Meier
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/das21a/das21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
