---
title: 'PixL2R: Guiding Reinforcement Learning Using Natural Language by Mapping Pixels
  to Rewards'
abstract: Reinforcement learning (RL), particularly in sparse reward settings, often
  requires prohibitively large numbers of interactions with the environment, thereby
  limiting its applicability to complex problems. To address this, several prior approaches
  have used natural language to guide the agentâ€™s exploration. However, these approaches
  typically operate on structured representations of the environment, and/or assume
  some structure in the natural language commands. In this work, we propose a model
  that directly maps pixels to rewards, given a free-form natural language description
  of the task, which can then be used for policy learning. Our experiments on the
  Meta-World robot manipulation domain show that  language-based rewards significantly
  improves the sample efficiency of policy learning, both in sparse and dense reward
  settings.
paperid: '104'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: goyal21a
month: 0
tex_title: 'PixL2R: Guiding Reinforcement Learning Using Natural Language by Mapping
  Pixels to Rewards'
firstpage: 485
lastpage: 497
page: 485-497
order: 485
cycles: false
bibtex_author: Goyal, Prasoon and Niekum, Scott and Mooney, Raymond
author:
- given: Prasoon
  family: Goyal
- given: Scott
  family: Niekum
- given: Raymond
  family: Mooney
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/goyal21a/goyal21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
