---
title: Learning Vision-based Reactive Policies for Obstacle Avoidance
abstract: In this paper, we address the problem of vision-based obstacle avoidance
  for robotic manipulators. This topic poses challenges for both perception and motion
  generation. While most work in the field aims at improving one of those aspects,
  we provide a unified framework for approaching this problem. The main goal of this
  framework is to connect perception and motion by identifying the relationship between
  the visual input and the corresponding motion representation. To this end, we propose
  a method for learning reactive obstacle avoidance policies. We evaluate our method
  on goal-reaching tasks for single and multiple obstacles scenarios. We show the
  ability of the proposed method to efficiently learn stable obstacle avoidance strategies
  at a high success rate while maintaining closed-loop responsiveness required for
  critical applications like human-robot interaction.
paperid: '454'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: aljalbout21a
month: 0
tex_title: Learning Vision-based Reactive Policies for Obstacle Avoidance
firstpage: 2040
lastpage: 2054
page: 2040-2054
order: 2040
cycles: false
bibtex_author: Aljalbout, Elie and Chen, Ji and Ritt, Konstantin and Ulmer, Maximilian
  and Haddadin, Sami
author:
- given: Elie
  family: Aljalbout
- given: Ji
  family: Chen
- given: Konstantin
  family: Ritt
- given: Maximilian
  family: Ulmer
- given: Sami
  family: Haddadin
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/aljalbout21a/aljalbout21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
