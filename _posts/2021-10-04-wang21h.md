---
title: 'TartanVO: A Generalizable Learning-based VO'
abstract: We present the first learning-based visual odometry (VO) model, which generalizes
  to multiple datasets and real-world scenarios and outperforms geometry-based methods
  in challenging scenes. We achieve this by leveraging the SLAM dataset TartanAir,
  which provides a large amount of diverse synthetic data in challenging environments.
  Furthermore, to make our VO model generalize across datasets, we propose an up-to-scale
  loss function and incorporate the camera intrinsic parameters into the model. Experiments
  show that a single model, TartanVO, trained only on synthetic data, without any
  finetuning, can be generalized to real-world datasets such as KITTI and EuRoC, demonstrating
  significant advantages over the geometry-based methods on challenging trajectories.
  Our code is available at https://github.com/castacks/tartanvo.
paperid: '395'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang21h
month: 0
tex_title: 'TartanVO: A Generalizable Learning-based VO'
firstpage: 1761
lastpage: 1772
page: 1761-1772
order: 1761
cycles: false
bibtex_author: Wang, Wenshan and Hu, Yaoyu and Scherer, Sebastian
author:
- given: Wenshan
  family: Wang
- given: Yaoyu
  family: Hu
- given: Sebastian
  family: Scherer
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/wang21h/wang21h.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
