---
title: Action-based Representation Learning for Autonomous Driving
abstract: Human drivers produce a vast amount of data which could, in principle, be
  used to improve autonomous driving systems. Unfortunately, seemingly straightforward
  approaches for creating end-to-end driving models that map sensor data directly
  into driving actions are problematic in terms of interpretability, and typically
  have significant difficulty dealing with spurious correlations. Alternatively, we
  propose to use this kind of action-based driving data for learning representations.
  Our experiments show that an affordance-based driving model pre-trained with this
  approach can leverage a relatively small amount of weakly annotated imagery and
  outperform pure end-to-end driving models, while being more interpretable. Further,
  we demonstrate how this strategy outperforms previous methods based on learning
  inverse dynamics models as well as other methods based on heavy human supervision
  (ImageNet).
paperid: '49'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xiao21a
month: 0
tex_title: Action-based Representation Learning for Autonomous Driving
firstpage: 232
lastpage: 246
page: 232-246
order: 232
cycles: false
bibtex_author: Xiao, Yi and Codevilla, Felipe and Pal, Christopher and Lopez, Antonio
author:
- given: Yi
  family: Xiao
- given: Felipe
  family: Codevilla
- given: Christopher
  family: Pal
- given: Antonio
  family: Lopez
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/xiao21a/xiao21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
