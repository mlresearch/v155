---
title: Chaining Behaviors from Data with Model-Free Reinforcement Learning
abstract: 'Reinforcement learning has been applied to a wide variety of robotics problems,
  but most of such applications involve collecting data from scratch for each new
  task. Since the amount of robot data we can collect for any single task is limited
  by time and cost considerations, the learned behavior is typically narrow: the policy
  can only execute the task in a handful of scenarios that it was trained on. What
  if there was a way to incorporate a large amount of prior data, either from previously
  solved tasks or from unsupervised or undirected environment interaction, to extend
  and generalize learned behaviors? While most prior work on extending robotic skills
  using pre-collected data focuses on building explicit hierarchies or skill decompositions,
  we show in this paper that we can reuse prior data to extend new skills simply through
  model-free reinforcement learning via dynamic programming. We show that even when
  the prior data does not actually succeed at solving the new task, it can still be
  utilized for learning a better policy, by providing the agent with a broader understanding
  of the mechanics of its environment. We demonstrate the effectiveness of such an
  approach by chaining together several behaviors seen in prior datasets for solving
  a new task, with our hardest experimental setting involving composing four robotic
  skills in a row: picking, placing, drawer opening, and grasping, where a +1/0 sparse
  reward is provided only on task completion. We train our policies in an end-to-end
  fashion, mapping high-dimensional image observations to low-level robot control
  commands, and present results in both simulated and real world domains.'
paperid: '481'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: singh21a
month: 0
tex_title: Chaining Behaviors from Data with Model-Free Reinforcement Learning
firstpage: 2162
lastpage: 2177
page: 2162-2177
order: 2162
cycles: false
bibtex_author: Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar,
  Aviral and Levine, Sergey
author:
- given: Avi
  family: Singh
- given: Albert
  family: Yu
- given: Jonathan
  family: Yang
- given: Jesse
  family: Zhang
- given: Aviral
  family: Kumar
- given: Sergey
  family: Levine
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/singh21a/singh21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
