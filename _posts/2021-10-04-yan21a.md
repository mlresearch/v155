---
title: Learning Predictive Representations for Deformable Objects Using Contrastive
  Estimation
abstract: Using visual model-based learning for deformable object manipulation is
  challenging due to difficulties in learning plannable visual representations along
  with complex dynamic models. In this work, we propose a new learning framework that
  jointly optimizes both the visual representation model and the dynamics model using
  contrastive estimation. Using simulation data collected by randomly perturbing deformable
  objects on a table, we learn latent dynamics models for these objects in an offline
  fashion. Then, using the learned models, we use simple model-based planning to solve
  challenging deformable object manipulation tasks such as spreading ropes and cloths.
  Experimentally, we show substantial improvements in performance over standard model-based
  learning techniques across our rope and cloth manipulation suite. Finally, we transfer
  our visual manipulation policies trained on data purely collected in simulation
  to a real PR2 robot through domain randomization.
paperid: '126'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yan21a
month: 0
tex_title: Learning Predictive Representations for Deformable Objects Using Contrastive
  Estimation
firstpage: 564
lastpage: 574
page: 564-574
order: 564
cycles: false
bibtex_author: Yan, Wilson and Vangipuram, Ashwin and Abbeel, Pieter and Pinto, Lerrel
author:
- given: Wilson
  family: Yan
- given: Ashwin
  family: Vangipuram
- given: Pieter
  family: Abbeel
- given: Lerrel
  family: Pinto
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/yan21a/yan21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
