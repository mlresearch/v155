---
title: 'ROLL: Visual Self-Supervised Reinforcement Learning with Object Reasoning'
abstract: Current image-based reinforcement learning (RL) algorithms typically operate
  on the whole image without performing object-level reasoning.  This leads to inefficient
  goal sampling and ineffective reward functions. In this paper, we improve upon previous
  visual self-supervised RL by incorporating object-level reasoning and occlusion
  reasoning. Specifically, we use unknown object segmentation to ignore distractors
  in the scene for better reward computation and goal generation; we further enable
  occlusion reasoning by employing a novel auxiliary loss and training scheme. We
  demonstrate that our proposed algorithm, ROLL (Reinforcement learning with Object
  Level Learning), learns dramatically faster and achieves better final performance
  compared with previous methods in several simulated visual control tasks. Project
  video and code are available at https://sites.google.com/andrew.cmu.edu/roll.
paperid: '215'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang21e
month: 0
tex_title: 'ROLL: Visual Self-Supervised Reinforcement Learning with Object Reasoning'
firstpage: 1030
lastpage: 1048
page: 1030-1048
order: 1030
cycles: false
bibtex_author: Wang, Yufei and Gautham, Narasimhan and Lin, Xingyu and Okorn, Brian
  and Held, David
author:
- given: Yufei
  family: Wang
- given: Narasimhan
  family: Gautham
- given: Xingyu
  family: Lin
- given: Brian
  family: Okorn
- given: David
  family: Held
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/wang21e/wang21e.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
