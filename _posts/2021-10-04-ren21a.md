---
title: Generalization Guarantees for Imitation Learning
abstract: Control policies from imitation learning can often fail to generalize to
  novel environments due to imperfect demonstrations or the inability of imitation
  learning algorithms to accurately infer the expert’s policies. In this paper, we
  present rigorous generalization guarantees for imitation learning by leveraging
  the Probably Approximately Correct (PAC)-Bayes framework to provide upper bounds
  on the expected cost of policies in novel environments. We propose a two-stage training
  method where a latent policy distribution is first embedded with multi-modal expert
  behavior using a conditional variational autoencoder, and then “fine-tuned” in new
  training environments to explicitly optimize the generalization bound. We demonstrate
  strong generalization bounds and their tightness relative to empirical performance
  in simulation for (i) grasping diverse mugs, (ii) planar pushing with visual feedback,
  and (iii) vision-based indoor navigation, as well as through hardware experiments
  for the two manipulation tasks.
paperid: '322'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ren21a
month: 0
tex_title: Generalization Guarantees for Imitation Learning
firstpage: 1426
lastpage: 1442
page: 1426-1442
order: 1426
cycles: false
bibtex_author: Ren, Allen and Veer, Sushant and Majumdar, Anirudha
author:
- given: Allen
  family: Ren
- given: Sushant
  family: Veer
- given: Anirudha
  family: Majumdar
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/ren21a/ren21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
