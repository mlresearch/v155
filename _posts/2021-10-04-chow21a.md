---
title: Safe Policy Learning for Continuous Control
abstract: We study continuous action reinforcement learning problems in which it is
  crucial that the agent interacts with the environment only through near-safe policies,
  i.e., policies that keep the agent in desirable situations, both during training
  and at convergence. We formulate these problems as {\em constrained} Markov decision
  processes (CMDPs) and present safe policy optimization algorithms that are based
  on a Lyapunov approach to solve them. Our algorithms can use any standard policy
  gradient (PG) method, such as deep deterministic policy gradient (DDPG) or proximal
  policy optimization (PPO), to train a neural network policy, while enforcing near-constraint
  satisfaction for every policy update by projecting either the policy parameter or
  the selected action onto the set of feasible solutions induced by the state-dependent
  linearized Lyapunov constraints. Compared to the existing constrained PG algorithms,
  ours are more data efficient as they are able to utilize both on-policy and off-policy
  data. Moreover, in practice our action-projection algorithm often leads to less
  conservative policy updates and allows for natural integration into an end-to-end
  PG training pipeline. We evaluate our algorithms and compare them with the state-of-the-art
  baselines on several simulated (MuJoCo) tasks, as well as a real-world robot obstacle-avoidance
  problem, demonstrating their effectiveness in terms of balancing performance and
  constraint satisfaction.
paperid: '171'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chow21a
month: 0
tex_title: Safe Policy Learning for Continuous Control
firstpage: 801
lastpage: 821
page: 801-821
order: 801
cycles: false
bibtex_author: Chow, Yinlam and Nachum, Ofir and Faust, Aleksandra and Due\~{n}ez-Guzman,
  Edgar and Ghavamzadeh, Mohammad
author:
- given: Yinlam
  family: Chow
- given: Ofir
  family: Nachum
- given: Aleksandra
  family: Faust
- given: Edgar
  family: Dueñez-Guzman
- given: Mohammad
  family: Ghavamzadeh
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/chow21a/chow21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
