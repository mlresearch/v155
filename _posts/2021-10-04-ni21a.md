---
title: 'f-IRL: Inverse Reinforcement Learning via State Marginal Matching'
abstract: Imitation learning is well-suited for robotic tasks where it is difficult
  to directly program the behavior or specify a cost for optimal control.  In this
  work, we propose a method for learning the reward function (and the corresponding
  policy) to match the expert state density. Our main result is the analytic gradient
  of any f-divergence between the agent and expert state distribution w.r.t. reward
  parameters. Based on the derived gradient, we present an algorithm, f-IRL, that
  recovers a stationary reward function from the expert density by gradient descent.
  We show that f-IRL can learn behaviors from a hand-designed target state density
  or implicitly through expert observations. Our method outperforms adversarial imitation
  learning methods in terms of sample efficiency and the required number of expert
  trajectories on IRL benchmarks. Moreover, we show that the recovered reward function
  can be used to quickly solve downstream tasks, and empirically demonstrate its utility
  on hard-to-explore tasks and for behavior transfer across changes in dynamics. Project
  videos and code link are available at https://sites.google.com/view/f-irl/home.
paperid: '111'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ni21a
month: 0
tex_title: 'f-IRL: Inverse Reinforcement Learning via State Marginal Matching'
firstpage: 529
lastpage: 551
page: 529-551
order: 529
cycles: false
bibtex_author: Ni, Tianwei and Sikchi, Harshit and Wang, Yufei and Gupta, Tejus and
  Lee, Lisa and Eysenbach, Ben
author:
- given: Tianwei
  family: Ni
- given: Harshit
  family: Sikchi
- given: Yufei
  family: Wang
- given: Tejus
  family: Gupta
- given: Lisa
  family: Lee
- given: Ben
  family: Eysenbach
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/ni21a/ni21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
