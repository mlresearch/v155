---
title: 'Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic Reinforcement
  Learning'
abstract: 'One of the great promises of robot learning systems is that they will be
  able to learn from their mistakes and continuously adapt to ever-changing environments.
  Despite this potential, most of the robot learning systems today produce static
  policies that are not further adapted during deployment, because the algorithms
  which produce those policies are not designed for continual adaptation. We present
  an adaptation method, and empirical evidence that it supports a robot learning framework
  for continual adaption. We show that this very simple method-fine-tuning off-policy
  reinforcement learning using offline datasetsâ€“is robust to changes in background,
  object shape and appearance, lighting conditions, and robot morphology. We demonstrate
  how to adapt vision-based robotic manipulation policies to new variations using
  less than 0.2% of the data necessary to learn the task from scratch. Furthermore,
  we demonstrate that this robustness holds in an episodic continual learning setting.
  We also show that pre-training via RL is essential: training from scratch or adapting
  from super vised ImageNet features are both unsuccessful with such small amounts
  of data. Our empirical conclusions are consistently supported by experiments on
  simulated manipulation tasks, and by 60 unique fine-tuning experiments on a real
  robotic grasping system pre-trained on 580,000 grasps. For video results and an
  overview of the methods and experiments in this study, see the project website at
  \url{https://ryanjulian.me/continual-fine-tuning}.'
paperid: '467'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: julian21a
month: 0
tex_title: 'Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic Reinforcement
  Learning'
firstpage: 2120
lastpage: 2136
page: 2120-2136
order: 2120
cycles: false
bibtex_author: Julian, Ryan and Swanson, Benjamin and Sukhatme, Gaurav and Levine,
  Sergey and Finn, Chelsea and Hausman, Karol
author:
- given: Ryan
  family: Julian
- given: Benjamin
  family: Swanson
- given: Gaurav
  family: Sukhatme
- given: Sergey
  family: Levine
- given: Chelsea
  family: Finn
- given: Karol
  family: Hausman
date: 2021-10-04
address:
container-title: Proceedings of the 2020 Conference on Robot Learning
volume: '155'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 10
  - 4
pdf: https://proceedings.mlr.press/v155/julian21a/julian21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
